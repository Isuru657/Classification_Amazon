{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n",
    "import nltk\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import WordNetLemmatizer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('datasets/Train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('datasets/Test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_uncommon_words(stringlist, max):\n",
    "    uncommon_words= {}\n",
    "    seen = {\"\"}\n",
    "    \n",
    "    for string in stringlist:\n",
    "        for word in nltk.word_tokenize(string):\n",
    "            count = uncommon_words.get(word)\n",
    "            if word not in seen: \n",
    "                seen.add(word)\n",
    "                uncommon_words.update({word: 1})\n",
    "            # If it's already been seen the max number of times, take it out of uncommon_words\n",
    "            elif count == max: \n",
    "                uncommon_words.pop(word)\n",
    "            # If it hasn't been seen max times, increment its count in uncommon_words\n",
    "            elif count is not None:\n",
    "                uncommon_words.update({word: count+1})\n",
    "    return uncommon_words.keys()\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>amazon-id</th>\n",
       "      <th>helpful</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>summary</th>\n",
       "      <th>price</th>\n",
       "      <th>categories</th>\n",
       "      <th>root-genre</th>\n",
       "      <th>title</th>\n",
       "      <th>artist</th>\n",
       "      <th>label</th>\n",
       "      <th>first-release-year</th>\n",
       "      <th>songs</th>\n",
       "      <th>salesRank</th>\n",
       "      <th>related</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-4984057859803657856</td>\n",
       "      <td>1877521326299865484</td>\n",
       "      <td>[2, 2]</td>\n",
       "      <td>1302739200</td>\n",
       "      <td>Very nice music for practicing my Tai Chi. I d...</td>\n",
       "      <td>4</td>\n",
       "      <td>04 14, 2011</td>\n",
       "      <td>Beautiful</td>\n",
       "      <td>16.47</td>\n",
       "      <td>['CDs &amp; Vinyl', 'New Age']</td>\n",
       "      <td>New Age</td>\n",
       "      <td>-3267874170410107454</td>\n",
       "      <td>-7180760356347753735</td>\n",
       "      <td>Cdbaby/Cdbaby</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[7058439142327364074, 6037075874942075284, 852...</td>\n",
       "      <td>27222</td>\n",
       "      <td>{'also_bought': [-404470919165672227, 11968160...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9136764282801708742</td>\n",
       "      <td>1877521326299865484</td>\n",
       "      <td>[11, 11]</td>\n",
       "      <td>1180396800</td>\n",
       "      <td>I recently starting doing Tai Chi which I love...</td>\n",
       "      <td>5</td>\n",
       "      <td>05 29, 2007</td>\n",
       "      <td>Tranquillity In Motion !!!</td>\n",
       "      <td>16.47</td>\n",
       "      <td>['CDs &amp; Vinyl', 'New Age']</td>\n",
       "      <td>New Age</td>\n",
       "      <td>-3267874170410107454</td>\n",
       "      <td>-7180760356347753735</td>\n",
       "      <td>Cdbaby/Cdbaby</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[7058439142327364074, 6037075874942075284, 852...</td>\n",
       "      <td>27222</td>\n",
       "      <td>{'also_bought': [-404470919165672227, 11968160...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2164551966908582519</td>\n",
       "      <td>1877521326299865484</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>1361404800</td>\n",
       "      <td>My wife uses it for her class room the kids lo...</td>\n",
       "      <td>5</td>\n",
       "      <td>02 21, 2013</td>\n",
       "      <td>Great Stuff</td>\n",
       "      <td>16.47</td>\n",
       "      <td>['CDs &amp; Vinyl', 'New Age']</td>\n",
       "      <td>New Age</td>\n",
       "      <td>-3267874170410107454</td>\n",
       "      <td>-7180760356347753735</td>\n",
       "      <td>Cdbaby/Cdbaby</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[7058439142327364074, 6037075874942075284, 852...</td>\n",
       "      <td>27222</td>\n",
       "      <td>{'also_bought': [-404470919165672227, 11968160...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-7309200698931694843</td>\n",
       "      <td>1877521326299865484</td>\n",
       "      <td>[4, 4]</td>\n",
       "      <td>1338163200</td>\n",
       "      <td>We bought this music to go Dr Lam DVD. The mus...</td>\n",
       "      <td>5</td>\n",
       "      <td>05 28, 2012</td>\n",
       "      <td>Beautiful</td>\n",
       "      <td>16.47</td>\n",
       "      <td>['CDs &amp; Vinyl', 'New Age']</td>\n",
       "      <td>New Age</td>\n",
       "      <td>-3267874170410107454</td>\n",
       "      <td>-7180760356347753735</td>\n",
       "      <td>Cdbaby/Cdbaby</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[7058439142327364074, 6037075874942075284, 852...</td>\n",
       "      <td>27222</td>\n",
       "      <td>{'also_bought': [-404470919165672227, 11968160...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-4461682407031037732</td>\n",
       "      <td>1877521326299865484</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>1396310400</td>\n",
       "      <td>It helps me do my exercise because it sets the...</td>\n",
       "      <td>5</td>\n",
       "      <td>04 1, 2014</td>\n",
       "      <td>tai chi music</td>\n",
       "      <td>16.47</td>\n",
       "      <td>['CDs &amp; Vinyl', 'New Age']</td>\n",
       "      <td>New Age</td>\n",
       "      <td>-3267874170410107454</td>\n",
       "      <td>-7180760356347753735</td>\n",
       "      <td>Cdbaby/Cdbaby</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[7058439142327364074, 6037075874942075284, 852...</td>\n",
       "      <td>27222</td>\n",
       "      <td>{'also_bought': [-404470919165672227, 11968160...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            reviewerID            amazon-id   helpful  unixReviewTime  \\\n",
       "0 -4984057859803657856  1877521326299865484    [2, 2]      1302739200   \n",
       "1  9136764282801708742  1877521326299865484  [11, 11]      1180396800   \n",
       "2  2164551966908582519  1877521326299865484    [0, 0]      1361404800   \n",
       "3 -7309200698931694843  1877521326299865484    [4, 4]      1338163200   \n",
       "4 -4461682407031037732  1877521326299865484    [0, 0]      1396310400   \n",
       "\n",
       "                                          reviewText  overall   reviewTime  \\\n",
       "0  Very nice music for practicing my Tai Chi. I d...        4  04 14, 2011   \n",
       "1  I recently starting doing Tai Chi which I love...        5  05 29, 2007   \n",
       "2  My wife uses it for her class room the kids lo...        5  02 21, 2013   \n",
       "3  We bought this music to go Dr Lam DVD. The mus...        5  05 28, 2012   \n",
       "4  It helps me do my exercise because it sets the...        5   04 1, 2014   \n",
       "\n",
       "                      summary  price                  categories root-genre  \\\n",
       "0                   Beautiful  16.47  ['CDs & Vinyl', 'New Age']    New Age   \n",
       "1  Tranquillity In Motion !!!  16.47  ['CDs & Vinyl', 'New Age']    New Age   \n",
       "2                 Great Stuff  16.47  ['CDs & Vinyl', 'New Age']    New Age   \n",
       "3                   Beautiful  16.47  ['CDs & Vinyl', 'New Age']    New Age   \n",
       "4               tai chi music  16.47  ['CDs & Vinyl', 'New Age']    New Age   \n",
       "\n",
       "                 title               artist          label  \\\n",
       "0 -3267874170410107454 -7180760356347753735  Cdbaby/Cdbaby   \n",
       "1 -3267874170410107454 -7180760356347753735  Cdbaby/Cdbaby   \n",
       "2 -3267874170410107454 -7180760356347753735  Cdbaby/Cdbaby   \n",
       "3 -3267874170410107454 -7180760356347753735  Cdbaby/Cdbaby   \n",
       "4 -3267874170410107454 -7180760356347753735  Cdbaby/Cdbaby   \n",
       "\n",
       "   first-release-year                                              songs  \\\n",
       "0                 NaN  [7058439142327364074, 6037075874942075284, 852...   \n",
       "1                 NaN  [7058439142327364074, 6037075874942075284, 852...   \n",
       "2                 NaN  [7058439142327364074, 6037075874942075284, 852...   \n",
       "3                 NaN  [7058439142327364074, 6037075874942075284, 852...   \n",
       "4                 NaN  [7058439142327364074, 6037075874942075284, 852...   \n",
       "\n",
       "   salesRank                                            related  \n",
       "0      27222  {'also_bought': [-404470919165672227, 11968160...  \n",
       "1      27222  {'also_bought': [-404470919165672227, 11968160...  \n",
       "2      27222  {'also_bought': [-404470919165672227, 11968160...  \n",
       "3      27222  {'also_bought': [-404470919165672227, 11968160...  \n",
       "4      27222  {'also_bought': [-404470919165672227, 11968160...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "handle_text: takes out stop words and punctuation, lemmatizes, and converts to lowercase\n",
    "* input: string\n",
    "* output: hanlded string\n",
    "\"\"\"\n",
    "def handle_text(text):\n",
    "    # Check that argument provided is a string\n",
    "    if not isinstance(text,str):\n",
    "        return \"\"\n",
    "    output = []\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    wordnet_lemmatizer = WordNetLemmatizer()\n",
    "    for word in nltk.word_tokenize(text): \n",
    "        # Disclude stop words and words with punctuation\n",
    "        word = word.lower()\n",
    "        if word not in stop_words and word.isalpha():\n",
    "            # Add lemmatized words\n",
    "            output.append(wordnet_lemmatizer.lemmatize(word))\n",
    "    return \" \".join(output) # return the list of words as one single string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "convert_text: applies handle_text to all summaries and reviews in dataframe\n",
    "* input: dataframe\n",
    "* output: new dataframe with converted summaries/reviews\n",
    "\"\"\"\n",
    "def convert_text(df):\n",
    "    df = df.assign(summary=df['summary'].apply(handle_text))\n",
    "    df = df.assign(reviewText=df['reviewText'].apply(handle_text))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "get_uncommon_words: gets all words that occur less than the 'max' times in the data\n",
    "* inputs: list_of_strings to get the uncommon words from\n",
    "         max: integer of the max number of times a word can occur and still be considered 'uncommon'\n",
    "* output: dictionary key set of uncommon words\n",
    "\"\"\"\n",
    "def get_uncommon_words(list_of_strings, max):\n",
    "    uncommon_words = {} # dictionary of uncommon words where key=word, item=frequency\n",
    "    seen = {\"\"} # set of 'seen' words to avoid re-adding words to uncommon_words\n",
    "    for string in list_of_strings:\n",
    "        for word in nltk.word_tokenize(string): \n",
    "            count = uncommon_words.get(word)\n",
    "            # If we haven't seen the word yet, add it to seen and uncommon_words\n",
    "            if word not in seen: \n",
    "                seen.add(word)\n",
    "                uncommon_words.update({word: 1})\n",
    "            # If it's already been seen the max number of times, take it out of uncommon_words\n",
    "            elif count == max: \n",
    "                uncommon_words.pop(word)\n",
    "            # If it hasn't been seen max times, increment its count in uncommon_words\n",
    "            elif count is not None:\n",
    "                uncommon_words.update({word: count+1})\n",
    "    return uncommon_words.keys() # return only the words, not the counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "remove_words: removes all words in provided list from a given string\n",
    "* inputs: string (to remove words from)\n",
    "          words_to_remove: list of strings indicating which words to remove\n",
    "* output: string (without provided words)\n",
    "\"\"\"\n",
    "def remove_words(string, words_to_remove):\n",
    "    list_of_words = nltk.word_tokenize(string)\n",
    "    for word in list_of_words: \n",
    "        # remove all words that occur in words_to_remove\n",
    "        if word in words_to_remove: \n",
    "            list_of_words.remove(word)\n",
    "    return \" \".join(list_of_words) # return as a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "remove_words_summaries: removes all words in provided list from the dataframe's summaries\n",
    "* inputs: dataframe (to remove words from)\n",
    "          words_to_remove: list of strings indicating which words to remove\n",
    "* output: new dataframe (without the given words)\n",
    "\"\"\"\n",
    "def remove_words_reviews(df, words_to_remove):\n",
    "    return df.assign(reviewText=df['reviewText'].apply(remove_words, words_to_remove=words_to_remove))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_df(df):\n",
    "    # Convert to lowercase, remove punctuation and stop words, lemmatize words\n",
    "    df = convert_text(df)\n",
    "    uncommon_words = get_uncommon_words(df['reviewText'], 2)\n",
    "     # Remove uncommon words\n",
    "    return remove_words_reviews(df, uncommon_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_new = prep_df(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>amazon-id</th>\n",
       "      <th>helpful</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>summary</th>\n",
       "      <th>price</th>\n",
       "      <th>categories</th>\n",
       "      <th>root-genre</th>\n",
       "      <th>title</th>\n",
       "      <th>artist</th>\n",
       "      <th>label</th>\n",
       "      <th>first-release-year</th>\n",
       "      <th>songs</th>\n",
       "      <th>salesRank</th>\n",
       "      <th>related</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-4984057859803657856</td>\n",
       "      <td>1877521326299865484</td>\n",
       "      <td>[2, 2]</td>\n",
       "      <td>1302739200</td>\n",
       "      <td>nice music practicing tai chi downloaded phone...</td>\n",
       "      <td>4</td>\n",
       "      <td>04 14, 2011</td>\n",
       "      <td>beautiful</td>\n",
       "      <td>16.47</td>\n",
       "      <td>['CDs &amp; Vinyl', 'New Age']</td>\n",
       "      <td>New Age</td>\n",
       "      <td>-3267874170410107454</td>\n",
       "      <td>-7180760356347753735</td>\n",
       "      <td>Cdbaby/Cdbaby</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[7058439142327364074, 6037075874942075284, 852...</td>\n",
       "      <td>27222</td>\n",
       "      <td>{'also_bought': [-404470919165672227, 11968160...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9136764282801708742</td>\n",
       "      <td>1877521326299865484</td>\n",
       "      <td>[11, 11]</td>\n",
       "      <td>1180396800</td>\n",
       "      <td>recently starting tai chi love adding cd pract...</td>\n",
       "      <td>5</td>\n",
       "      <td>05 29, 2007</td>\n",
       "      <td>tranquillity motion</td>\n",
       "      <td>16.47</td>\n",
       "      <td>['CDs &amp; Vinyl', 'New Age']</td>\n",
       "      <td>New Age</td>\n",
       "      <td>-3267874170410107454</td>\n",
       "      <td>-7180760356347753735</td>\n",
       "      <td>Cdbaby/Cdbaby</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[7058439142327364074, 6037075874942075284, 852...</td>\n",
       "      <td>27222</td>\n",
       "      <td>{'also_bought': [-404470919165672227, 11968160...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2164551966908582519</td>\n",
       "      <td>1877521326299865484</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>1361404800</td>\n",
       "      <td>wife us class room kid love loved price great ...</td>\n",
       "      <td>5</td>\n",
       "      <td>02 21, 2013</td>\n",
       "      <td>great stuff</td>\n",
       "      <td>16.47</td>\n",
       "      <td>['CDs &amp; Vinyl', 'New Age']</td>\n",
       "      <td>New Age</td>\n",
       "      <td>-3267874170410107454</td>\n",
       "      <td>-7180760356347753735</td>\n",
       "      <td>Cdbaby/Cdbaby</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[7058439142327364074, 6037075874942075284, 852...</td>\n",
       "      <td>27222</td>\n",
       "      <td>{'also_bought': [-404470919165672227, 11968160...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-7309200698931694843</td>\n",
       "      <td>1877521326299865484</td>\n",
       "      <td>[4, 4]</td>\n",
       "      <td>1338163200</td>\n",
       "      <td>bought music go dr lam dvd music perfect give ...</td>\n",
       "      <td>5</td>\n",
       "      <td>05 28, 2012</td>\n",
       "      <td>beautiful</td>\n",
       "      <td>16.47</td>\n",
       "      <td>['CDs &amp; Vinyl', 'New Age']</td>\n",
       "      <td>New Age</td>\n",
       "      <td>-3267874170410107454</td>\n",
       "      <td>-7180760356347753735</td>\n",
       "      <td>Cdbaby/Cdbaby</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[7058439142327364074, 6037075874942075284, 852...</td>\n",
       "      <td>27222</td>\n",
       "      <td>{'also_bought': [-404470919165672227, 11968160...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-4461682407031037732</td>\n",
       "      <td>1877521326299865484</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>1396310400</td>\n",
       "      <td>help exercise set proper mood happy quality pl...</td>\n",
       "      <td>5</td>\n",
       "      <td>04 1, 2014</td>\n",
       "      <td>tai chi music</td>\n",
       "      <td>16.47</td>\n",
       "      <td>['CDs &amp; Vinyl', 'New Age']</td>\n",
       "      <td>New Age</td>\n",
       "      <td>-3267874170410107454</td>\n",
       "      <td>-7180760356347753735</td>\n",
       "      <td>Cdbaby/Cdbaby</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[7058439142327364074, 6037075874942075284, 852...</td>\n",
       "      <td>27222</td>\n",
       "      <td>{'also_bought': [-404470919165672227, 11968160...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            reviewerID            amazon-id   helpful  unixReviewTime  \\\n",
       "0 -4984057859803657856  1877521326299865484    [2, 2]      1302739200   \n",
       "1  9136764282801708742  1877521326299865484  [11, 11]      1180396800   \n",
       "2  2164551966908582519  1877521326299865484    [0, 0]      1361404800   \n",
       "3 -7309200698931694843  1877521326299865484    [4, 4]      1338163200   \n",
       "4 -4461682407031037732  1877521326299865484    [0, 0]      1396310400   \n",
       "\n",
       "                                          reviewText  overall   reviewTime  \\\n",
       "0  nice music practicing tai chi downloaded phone...        4  04 14, 2011   \n",
       "1  recently starting tai chi love adding cd pract...        5  05 29, 2007   \n",
       "2  wife us class room kid love loved price great ...        5  02 21, 2013   \n",
       "3  bought music go dr lam dvd music perfect give ...        5  05 28, 2012   \n",
       "4  help exercise set proper mood happy quality pl...        5   04 1, 2014   \n",
       "\n",
       "               summary  price                  categories root-genre  \\\n",
       "0            beautiful  16.47  ['CDs & Vinyl', 'New Age']    New Age   \n",
       "1  tranquillity motion  16.47  ['CDs & Vinyl', 'New Age']    New Age   \n",
       "2          great stuff  16.47  ['CDs & Vinyl', 'New Age']    New Age   \n",
       "3            beautiful  16.47  ['CDs & Vinyl', 'New Age']    New Age   \n",
       "4        tai chi music  16.47  ['CDs & Vinyl', 'New Age']    New Age   \n",
       "\n",
       "                 title               artist          label  \\\n",
       "0 -3267874170410107454 -7180760356347753735  Cdbaby/Cdbaby   \n",
       "1 -3267874170410107454 -7180760356347753735  Cdbaby/Cdbaby   \n",
       "2 -3267874170410107454 -7180760356347753735  Cdbaby/Cdbaby   \n",
       "3 -3267874170410107454 -7180760356347753735  Cdbaby/Cdbaby   \n",
       "4 -3267874170410107454 -7180760356347753735  Cdbaby/Cdbaby   \n",
       "\n",
       "   first-release-year                                              songs  \\\n",
       "0                 NaN  [7058439142327364074, 6037075874942075284, 852...   \n",
       "1                 NaN  [7058439142327364074, 6037075874942075284, 852...   \n",
       "2                 NaN  [7058439142327364074, 6037075874942075284, 852...   \n",
       "3                 NaN  [7058439142327364074, 6037075874942075284, 852...   \n",
       "4                 NaN  [7058439142327364074, 6037075874942075284, 852...   \n",
       "\n",
       "   salesRank                                            related  \n",
       "0      27222  {'also_bought': [-404470919165672227, 11968160...  \n",
       "1      27222  {'also_bought': [-404470919165672227, 11968160...  \n",
       "2      27222  {'also_bought': [-404470919165672227, 11968160...  \n",
       "3      27222  {'also_bought': [-404470919165672227, 11968160...  \n",
       "4      27222  {'also_bought': [-404470919165672227, 11968160...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def awesome_products(df):\n",
    "    df = df.groupby('amazon-id').agg({'overall': lambda x: 1 if np.mean(x) > 4.5 else 0})\n",
    "    return df['overall']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def combine_summaries(train_df, test_df):\n",
    "#    df, vestorizer\n",
    "    #aggregate reviewTest based on amazon-id\n",
    "    combined_train_df = train_df.groupby('amazon-id').agg({'reviewText': ' '.join, 'summary': ' '.join})\n",
    "    vectorizer = TfidfVectorizer(max_features=8000)\n",
    "    \n",
    "    #transform it into an np.array then fit it into matrix\n",
    "    review_vector = np.array(vectorizer.fit_transform(combined_train_df['reviewText']).toarray())\n",
    "    #saved_train_matrix = vectorizer.fit(combined_train_df['reviewText'])\n",
    "    summary_vector = np.array(vectorizer.transform(combined_train_df['summary']).toarray())\n",
    "    \n",
    "    \n",
    "    train_vector = review_vector + summary_vector\n",
    "    #train_vector = np.array(vectorizer.fit_transform(combined_train_df['reviewText']).toarray())\n",
    "    \n",
    "    combined_test_df = test_df.groupby('amazon-id').agg({'reviewText': ' '.join, 'summary': ' '.join})\n",
    "\n",
    "    #transform it into an np.array then fit it into matrix\n",
    "    review_vector = np.array(vectorizer.fit_transform(combined_test_df['reviewText']).toarray())\n",
    "    #saved_test_matrix = vectorizer.fit(combined_test_df['reviewText'])\n",
    "    summary_test_vector = np.array(vectorizer.transform(combined_test_df['summary']).toarray())\n",
    "\n",
    "    #combine review and summary\n",
    "    test_vector = np.array(vectorizer.fit_transform(combined_test_df['reviewText']).toarray())\n",
    "    print(\"Test vector length: \", len(test_vector))\n",
    "    print(\"Train vector length: \", len(train_vector))\n",
    "    return train_vector, test_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_train_df = train_new.groupby('amazon-id').agg({'reviewText': ' '.join, 'summary': ' '.join, 'salesRank': lambda x: np.mean(x), 'price': lambda x: np.mean(x)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "ct_opts = [('reviewText_bow', TfidfVectorizer(max_features = 4000), 'reviewText'),\n",
    "          ('summary_bow', TfidfVectorizer(max_features = 4000), 'summary'),\n",
    "          ('salesRank_norm', MinMaxScaler(), ['salesRank']),\n",
    "          ('price_norm', MinMaxScaler(), ['price'])]\n",
    "ct = ColumnTransformer(ct_opts, remainder = 'drop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vec = np.array(ct.fit_transform(combined_train_df).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         ... 0.         0.53410938 0.01719522]\n",
      " [0.         0.         0.         ... 0.         0.12598976 0.0836289 ]\n",
      " [0.         0.         0.         ... 0.         0.11423985 0.02755755]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.24462838 0.02463662]\n",
      " [0.         0.         0.         ... 0.         0.1105543  0.02783573]\n",
      " [0.         0.         0.         ... 0.         0.24037958 0.02303707]]\n"
     ]
    }
   ],
   "source": [
    "print(train_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prediction(x_train, y_train, x_test):\n",
    "    model = LinearSVC()\n",
    "    model.fit(x_train, y_train)\n",
    "    return model, model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10543, 8002)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "aw = awesome_products(train_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10543,)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import confusion_matrix, f1_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(train_vec, aw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, y_pred = make_prediction(x_train, y_train, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score= 0.7349936143039592\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.59      0.61      1101\n",
      "           1       0.72      0.75      0.73      1535\n",
      "\n",
      "    accuracy                           0.69      2636\n",
      "   macro avg       0.68      0.67      0.67      2636\n",
      "weighted avg       0.68      0.69      0.68      2636\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"f1_score=\", f1_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
